{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125b9d3d-6d56-453b-8ab4-b89da988f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''VGG11/13/16/19 in Pytorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db73bcd-5653-40af-81d6-8db0710b4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weight_Matrix(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Weight_Matrix, self).__init__()\n",
    "        self.layer = 0\n",
    "        self.padding = nn.ZeroPad2d(2)\n",
    "        temp_path = \"./checkpoint/Cifar10_VGG19_No_Error.pth\"\n",
    "        temp_matrix = torch.load(temp_path)['net']['module.features.{}.weight'.format(self.layer)][:,:,:,:]\n",
    "        temp_matrix = temp_matrix.reshape((8,8,3,3,3))\n",
    "        temp_matrix = temp_matrix.permute(2,0,3,1,4)\n",
    "        temp_matrix = temp_matrix.reshape((1,3,24,24))\n",
    "        temp_matrix = torch.abs(temp_matrix)\n",
    "        temp_matrix = [temp_matrix] * 17\n",
    "        temp_matrix = torch.cat(temp_matrix, dim=0)\n",
    "        self.input_matrix = self._onehot_padding(temp_matrix)\n",
    "        self.weight_decision1 = nn.Sequential(\n",
    "                                              nn.Conv2d(in_channels=3, out_channels=3, kernel_size=5, stride=5, padding=0, dilation=1, groups=1),\n",
    "                                              nn.LayerNorm((3,24,24), elementwise_affine=True),\n",
    "                                             )\n",
    "        self.weight_decision2 = nn.Sequential(\n",
    "                                              nn.Conv2d(in_channels=3, out_channels=3, kernel_size=5, stride=5, padding=0, dilation=1, groups=1),\n",
    "                                              nn.LayerNorm((3,24,24), elementwise_affine=True),\n",
    "                                             )\n",
    "        self.weight_decision3 = nn.Sequential(\n",
    "                                              nn.Conv2d(in_channels=3, out_channels=3, kernel_size=5, stride=5, padding=0, dilation=1, groups=1),\n",
    "                                              nn.LayerNorm((3,24,24), elementwise_affine=True),\n",
    "                                             )\n",
    "        self.weight_decision4 = nn.Sequential(\n",
    "                                              nn.Conv2d(in_channels=3, out_channels=3, kernel_size=5, stride=5, padding=0, dilation=1, groups=1),\n",
    "                                              nn.LayerNorm((3,24,24), elementwise_affine=True),\n",
    "                                             )\n",
    "    def forward(self):\n",
    "        out = self.weight_decision1(self.input_matrix)\n",
    "        out = self.weight_decision2(self._onehot_padding(out))\n",
    "        out = self.weight_decision3(self._onehot_padding(out))\n",
    "        out = self.weight_decision4(self._onehot_padding(out))\n",
    "        return out\n",
    "    def _onehot_padding(self, x):\n",
    "        out = x.reshape((17,3,24*24,1,1,))\n",
    "        out = self.padding(out)\n",
    "        out[0,:,:,0,0] = 1.0\n",
    "        out[1,:,:,0,1] = 1.0\n",
    "        out[2,:,:,0,2] = 1.0\n",
    "        out[3,:,:,0,3] = 1.0\n",
    "        out[4,:,:,0,4] = 1.0\n",
    "        out[5,:,:,1,0] = 1.0\n",
    "        out[6,:,:,1,1] = 1.0\n",
    "        out[7,:,:,1,2] = 1.0\n",
    "        out[8,:,:,1,3] = 1.0\n",
    "        out[9,:,:,1,4] = 1.0\n",
    "        out[10,:,:,2,0] = 1.0\n",
    "        out[11,:,:,2,1] = 1.0\n",
    "        out[12,:,:,2,3] = 1.0\n",
    "        out[13,:,:,2,4] = 1.0\n",
    "        out[14,:,:,3,0] = 1.0\n",
    "        out[15,:,:,3,1] = 1.0\n",
    "        out[16,:,:,3,2] = 1.0\n",
    "        out = out.reshape((17,3,24,24,5,5))\n",
    "        out = out.permute(0,1,2,4,3,5)\n",
    "        out = out.reshape((17,3,24*5,24*5))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682aeae8-1b12-46eb-aa41-b07cb4bb23ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Building model..\n",
      "Epoch: 8666, Loss: 0.0013472529826685786\r"
     ]
    }
   ],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "PATH = \"D:/Jupyter_Data/data\"\n",
    "device = \"cuda\"\n",
    "\n",
    "best_loss = 10 ** 8 # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "weight_batch_size = 17\n",
    "Batch_Size = 50\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=PATH, train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=Batch_Size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=PATH, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=Batch_Size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net = VGG('VGG19')\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "wet = Weight_Matrix().to(device)\n",
    "\n",
    "quant = 0.002\n",
    "# Load\n",
    "layer = 0\n",
    "output_list = [\"No\", 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "    \n",
    "target_matrix = torch.empty((17,3,24,24), dtype=torch.float32)\n",
    "mem_matrix = torch.empty((17,3,24,24), dtype=torch.float32).to(device)\n",
    "for n, i in enumerate(output_list):\n",
    "    temp_path = \"./checkpoint/Cifar10_VGG19_{}_Error.pth\".format(i)\n",
    "    temp_matrix = torch.load(temp_path)['net']['module.features.{}.weight'.format(layer)][:,:,:,:]\n",
    "    temp_matrix = temp_matrix.reshape((8,8,3,3,3))\n",
    "    temp_matrix = temp_matrix.permute(2,0,3,1,4)\n",
    "    temp_matrix = temp_matrix.reshape((3,24,24))\n",
    "    mem_matrix[n,:,:,:] = temp_matrix / torch.abs(temp_matrix)\n",
    "    target_matrix[n,:,:,:] = torch.abs(temp_matrix[:,:,:])\n",
    "\n",
    "criterion_net = nn.CrossEntropyLoss()\n",
    "criterion_wet = nn.MSELoss()\n",
    "#criterion_wet = nn.L1Loss()\n",
    "optimizer_net = optim.SGD(net.parameters(), lr=1e-3,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "optimizer_wet = optim.SGD(wet.parameters(), lr=1e-2,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler_net = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_net, T_max=200)\n",
    "scheduler_wet = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_wet, T_max=17)\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    wet.train()\n",
    "    optimizer_wet.zero_grad()\n",
    "    targets = target_matrix.to(device)\n",
    "    outputs = wet()\n",
    "    loss = criterion_wet(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer_wet.step()\n",
    "    print(\"Epoch: {}, Loss: {}\".format(epoch, loss), end=\"\\r\")\n",
    "\n",
    "def test(epoch):\n",
    "    global best_loss\n",
    "    wet.eval()\n",
    "    with torch.no_grad():\n",
    "        targets = target_matrix.to(device)\n",
    "        outputs = wet()\n",
    "        loss = criterion_wet(outputs, targets)\n",
    "    if (loss < best_loss):\n",
    "        best_loss = loss\n",
    "        state = {\n",
    "            'wet': wet.state_dict(),\n",
    "            'loss': loss,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, file_path)\n",
    "    \n",
    "def result_test():\n",
    "    wet.load_state_dict(torch.load(file_path)['wet'])\n",
    "    wet.eval()\n",
    "    with torch.no_grad():\n",
    "        weights = wet()\n",
    "    weights = weights * mem_matrix\n",
    "    weights = weights.reshape((17,3,8,3,8,3))\n",
    "    weights = weights.permute(0,2,4,1,3,5)\n",
    "    weights = weights.reshape((17,64,3,3,3))\n",
    "    \n",
    "    for n, i in enumerate(output_list):\n",
    "        target_path = './checkpoint/Cifar10_VGG19_{}_Error.pth'.format(i)\n",
    "        state_dict = torch.load(target_path)['net']\n",
    "        state_dict['module.features.{}.weight'.format(layer)] = weights[n,:,:,:,:]\n",
    "        net.load_state_dict(state_dict)\n",
    "        net.eval()\n",
    "        print(\"\\nError {}\".format(i))\n",
    "        \n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                if (i == \"No\"):\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = net(inputs)\n",
    "                else:\n",
    "                    temp = torch.empty((len(inputs),3,32,32,), dtype=torch.float32)\n",
    "                    for i in range(len(inputs)):\n",
    "                        temp[i,:] = transforms.functional.erase(inputs[i,:], 2*i, 0, 2, 32, 0.0)\n",
    "                    temp, targets = temp.to(device), targets.to(device)\n",
    "                    outputs = net(temp)\n",
    "                loss = criterion_net(outputs, targets)\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                    test_loss, correct, len(testloader.dataset),\n",
    "                    100. * correct / (len(testloader.dataset))), end=\"\\r\")\n",
    "\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "Epoch = 10 ** 5\n",
    "\n",
    "file_path = './checkpoint/Cifar10_VGG19_Weight_ConvNormConv.pth'\n",
    "best_loss = 10000.0\n",
    "start_time = time.time()\n",
    "for epoch in range(Epoch):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "result_test()\n",
    "end_time = time.time()\n",
    "print(\"Total Time = {}\".format(end_time - start_time))\n",
    "\n",
    "for key, val in wet.state_dict().items():\n",
    "    print(val.shape)\n",
    "print(\"Before Parameter Size = {}\".format(17*64*3*3*3 + 17*3))\n",
    "print(\" After Parameter Size = {}\".format(6*(3*24*24*3+225+3)))\n",
    "\n",
    "wet.eval()\n",
    "with torch.no_grad():\n",
    "    targets = target_matrix.to(device)\n",
    "    outputs = wet(inputs)\n",
    "print(outputs[0,0,:5,:5])\n",
    "print(target_matrix[0,0,:5,:5])\n",
    "print(outputs[1,0,:5,:5])\n",
    "print(target_matrix[1,0,:5,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2942af-053e-486d-b7af-8233fac64705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
