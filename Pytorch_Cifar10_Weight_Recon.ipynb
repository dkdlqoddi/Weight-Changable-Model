{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125b9d3d-6d56-453b-8ab4-b89da988f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''VGG11/13/16/19 in Pytorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db73bcd-5653-40af-81d6-8db0710b4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weight_Matrix(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Weight_Matrix, self).__init__()\n",
    "        self.weight_decision = nn.Sequential(\n",
    "                                             nn.Conv2d(in_channels=12, out_channels=3, kernel_size=5, stride=5, padding=0, dilation=1, groups=1),\n",
    "                                             #nn.ReLU(inplace=True),\n",
    "                                             nn.LayerNorm((3,24,24), elementwise_affine=True),\n",
    "                                            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.weight_decision(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682aeae8-1b12-46eb-aa41-b07cb4bb23ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Building model..\n",
      "Weight Matrix Shape = torch.Size([3, 24, 24])\n",
      "tensor([[0.0409, 0.0074, 0.0609, 0.1106, 0.0990],\n",
      "        [0.1365, 0.0398, 0.0056, 0.0507, 0.0963],\n",
      "        [0.1797, 0.1427, 0.0687, 0.0290, 0.0366],\n",
      "        [0.0494, 0.1255, 0.0864, 0.0086, 0.1332],\n",
      "        [0.0545, 0.0877, 0.1015, 0.0191, 0.0952]])\n",
      "tensor([[0.0708, 0.0566, 0.0683, 0.0671, 0.0647],\n",
      "        [0.0266, 0.0403, 0.0118, 0.0536, 0.0355],\n",
      "        [0.0264, 0.1062, 0.0401, 0.1032, 0.0426],\n",
      "        [0.0622, 0.1487, 0.0187, 0.0539, 0.1164],\n",
      "        [0.1539, 0.0973, 0.0725, 0.1115, 0.0838]])\n",
      "tensor([[-1., -1.,  1., -1., -1.],\n",
      "        [-1.,  1., -1.,  1.,  1.],\n",
      "        [ 1., -1.,  1., -1., -1.],\n",
      "        [-1., -1.,  1.,  1.,  1.],\n",
      "        [ 1., -1., -1., -1., -1.]], device='cuda:0')\n",
      "Epoch: 99999, Loss: 0.033229224383831024\n",
      "Error No\n",
      "Test set: Average loss: 656.4218, Accuracy: 3954/10000 (40%)\n",
      "Error 0\n",
      "Test set: Average loss: 717.6611, Accuracy: 3579/10000 (36%)\n",
      "Error 1\n",
      "Test set: Average loss: 774.8805, Accuracy: 3400/10000 (34%)\n",
      "Error 2\n",
      "Test set: Average loss: 561.2224, Accuracy: 4503/10000 (45%)\n",
      "Error 3\n",
      "Test set: Average loss: 499.4177, Accuracy: 4683/10000 (47%)\n",
      "Error 4\n",
      "Test set: Average loss: 621.4115, Accuracy: 4170/10000 (42%)\n",
      "Error 5\n",
      "Test set: Average loss: 600.8027, Accuracy: 3578/10000 (36%)\n",
      "Error 6\n",
      "Test set: Average loss: 602.9037, Accuracy: 3870/10000 (39%)\n",
      "Error 7\n",
      "Test set: Average loss: 879.1362, Accuracy: 2531/10000 (25%)\n",
      "Error 8\n",
      "Test set: Average loss: 1303.4925, Accuracy: 1378/10000 (14%)\n",
      "Error 9\n",
      "Test set: Average loss: 993.4717, Accuracy: 2536/10000 (25%)\n",
      "Error 10\n",
      "Test set: Average loss: 1049.5545, Accuracy: 2302/10000 (23%)\n",
      "Error 11\n",
      "Test set: Average loss: 575.5329, Accuracy: 3916/10000 (39%)\n",
      "Error 12\n",
      "Test set: Average loss: 501.2017, Accuracy: 4963/10000 (50%)\n",
      "Error 13\n",
      "Test set: Average loss: 698.5642, Accuracy: 3235/10000 (32%)\n",
      "Error 14\n",
      "Test set: Average loss: 723.8290, Accuracy: 2879/10000 (29%)\n",
      "Error 15\n",
      "Total Time = 647.264593362808228, Accuracy: 3452/10000 (35%)\n",
      "torch.Size([3, 12, 5, 5])\n",
      "torch.Size([3])\n",
      "torch.Size([3, 24, 24])\n",
      "torch.Size([3, 24, 24])\n",
      "29376\n",
      "tensor([[0.0489, 0.0551, 0.0580, 0.0669, 0.0292],\n",
      "        [0.0437, 0.0458, 0.0527, 0.0651, 0.0704],\n",
      "        [0.0490, 0.0630, 0.0493, 0.0475, 0.0366],\n",
      "        [0.0567, 0.0658, 0.0414, 0.0417, 0.0526],\n",
      "        [0.0453, 0.0486, 0.0619, 0.0444, 0.0614]], device='cuda:0')\n",
      "tensor([[0.0409, 0.0074, 0.0609, 0.1106, 0.0990],\n",
      "        [0.1365, 0.0398, 0.0056, 0.0507, 0.0963],\n",
      "        [0.1797, 0.1427, 0.0687, 0.0290, 0.0366],\n",
      "        [0.0494, 0.1255, 0.0864, 0.0086, 0.1332],\n",
      "        [0.0545, 0.0877, 0.1015, 0.0191, 0.0952]])\n",
      "tensor([[0.0531, 0.0593, 0.0621, 0.0711, 0.0334],\n",
      "        [0.0479, 0.0499, 0.0569, 0.0693, 0.0746],\n",
      "        [0.0532, 0.0672, 0.0535, 0.0517, 0.0407],\n",
      "        [0.0609, 0.0700, 0.0456, 0.0458, 0.0568],\n",
      "        [0.0495, 0.0528, 0.0661, 0.0486, 0.0656]], device='cuda:0')\n",
      "tensor([[0.0708, 0.0566, 0.0683, 0.0671, 0.0647],\n",
      "        [0.0266, 0.0403, 0.0118, 0.0536, 0.0355],\n",
      "        [0.0264, 0.1062, 0.0401, 0.1032, 0.0426],\n",
      "        [0.0622, 0.1487, 0.0187, 0.0539, 0.1164],\n",
      "        [0.1539, 0.0973, 0.0725, 0.1115, 0.0838]])\n"
     ]
    }
   ],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "PATH = \"D:/Jupyter_Data/data\"\n",
    "device = \"cuda\"\n",
    "\n",
    "best_loss = 10 ** 8 # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "weight_batch_size = 17\n",
    "Batch_Size = 50\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=PATH, train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=Batch_Size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=PATH, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=Batch_Size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net = VGG('VGG19')\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "wet = Weight_Matrix().to(device)\n",
    "\n",
    "quant = 0.002\n",
    "# Load\n",
    "layer = 0\n",
    "output_list = [\"No\", 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "temp_path = \"./checkpoint/Cifar10_VGG19_No_Error.pth\"\n",
    "temp_matrix = torch.load(temp_path)['net']['module.features.{}.weight'.format(layer)][:,:,:,:]\n",
    "temp_matrix = temp_matrix.reshape((8,8,3,3,3))\n",
    "temp_matrix = temp_matrix.permute(2,0,3,1,4)\n",
    "temp_matrix = temp_matrix.reshape((3,24,24))\n",
    "temp_matrix = torch.abs(temp_matrix)\n",
    "print(\"Weight Matrix Shape = {}\".format(temp_matrix.shape))\n",
    "\n",
    "input_matrix = torch.empty((17,12,24*5,24*5), dtype=torch.float32)\n",
    "for i in range(17):\n",
    "    for r in range(24):\n",
    "        for c in range(24):\n",
    "            input_matrix[i,:3,5*r,5*c] = temp_matrix[:,r,c]\n",
    "            input_matrix[i,:3,5*r+int((i+1)/5),5*c+(i+1)%5] = 1.0\n",
    "    input_matrix[i,3,:,:] = torch.pow(input_matrix[i,0,:,:],2)\n",
    "    input_matrix[i,4,:,:] = torch.pow(input_matrix[i,0,:,:],3)\n",
    "    input_matrix[i,5,:,:] = torch.pow(input_matrix[i,0,:,:],4)\n",
    "    input_matrix[i,6,:,:] = torch.pow(input_matrix[i,1,:,:],2)\n",
    "    input_matrix[i,7,:,:] = torch.pow(input_matrix[i,1,:,:],3)\n",
    "    input_matrix[i,8,:,:] = torch.pow(input_matrix[i,1,:,:],4)\n",
    "    input_matrix[i,9,:,:] = torch.pow(input_matrix[i,2,:,:],2)\n",
    "    input_matrix[i,10,:,:] = torch.pow(input_matrix[i,2,:,:],3)\n",
    "    input_matrix[i,11,:,:] = torch.pow(input_matrix[i,2,:,:],4)\n",
    "    \n",
    "target_matrix = torch.empty((17,3,24,24), dtype=torch.float32)\n",
    "mem_matrix = torch.empty((17,3,24,24), dtype=torch.float32).to(device)\n",
    "for n, i in enumerate(output_list):\n",
    "    temp_path = \"./checkpoint/Cifar10_VGG19_{}_Error.pth\".format(i)\n",
    "    temp_matrix = torch.load(temp_path)['net']['module.features.{}.weight'.format(layer)][:,:,:,:]\n",
    "    temp_matrix = temp_matrix.reshape((8,8,3,3,3))\n",
    "    temp_matrix = temp_matrix.permute(2,0,3,1,4)\n",
    "    temp_matrix = temp_matrix.reshape((3,24,24))\n",
    "    mem_matrix[n,:,:,:] = temp_matrix / torch.abs(temp_matrix)\n",
    "    target_matrix[n,:,:,:] = torch.abs(temp_matrix[:,:,:])\n",
    "\n",
    "criterion_net = nn.CrossEntropyLoss()\n",
    "#criterion_wet = nn.MSELoss()\n",
    "criterion_wet = nn.L1Loss()\n",
    "optimizer_net = optim.SGD(net.parameters(), lr=1e-3,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "optimizer_wet = optim.SGD(wet.parameters(), lr=1e-3,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler_net = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_net, T_max=200)\n",
    "scheduler_wet = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_wet, T_max=200)\n",
    "\n",
    "# Training\n",
    "def train(epoch, e):\n",
    "    wet.train()\n",
    "    optimizer_wet.zero_grad()\n",
    "    inputs, targets = input_matrix.to(device), target_matrix.to(device)\n",
    "    outputs = wet(inputs)\n",
    "    loss = criterion_wet(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer_wet.step()\n",
    "    print(\"Epoch: {}, Loss: {}\".format(epoch, loss), end=\"\\r\")\n",
    "\n",
    "def test(epoch, e):\n",
    "    global best_loss\n",
    "    wet.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs, targets = input_matrix.to(device), target_matrix.to(device)\n",
    "        outputs = wet(inputs)\n",
    "        loss = criterion_wet(outputs, targets)\n",
    "    if (loss < best_loss):\n",
    "        best_loss = loss\n",
    "        state = {\n",
    "            'wet': wet.state_dict(),\n",
    "            'loss': loss,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, file_path)\n",
    "    \n",
    "def result_test():\n",
    "    wet.load_state_dict(torch.load(file_path)['wet'])\n",
    "    wet.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = input_matrix.to(device)\n",
    "        weights = wet(inputs)\n",
    "    weights = weights * mem_matrix\n",
    "    weights = weights.reshape((17,3,8,3,8,3))\n",
    "    weights = weights.permute(0,2,4,1,3,5)\n",
    "    weights = weights.reshape((17,64,3,3,3))\n",
    "    \n",
    "    for n, i in enumerate(output_list):\n",
    "        target_path = './checkpoint/Cifar10_VGG19_{}_Error.pth'.format(i)\n",
    "        state_dict = torch.load(target_path)['net']\n",
    "        state_dict['module.features.{}.weight'.format(layer)] = weights[n,:,:,:,:]\n",
    "        net.load_state_dict(state_dict)\n",
    "        net.eval()\n",
    "        print(\"\\nError {}\".format(i))\n",
    "        \n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                if (i == \"No\"):\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = net(inputs)\n",
    "                else:\n",
    "                    temp = torch.empty((len(inputs),3,32,32,), dtype=torch.float32)\n",
    "                    for i in range(len(inputs)):\n",
    "                        temp[i,:] = transforms.functional.erase(inputs[i,:], 2*i, 0, 2, 32, 0.0)\n",
    "                    temp, targets = temp.to(device), targets.to(device)\n",
    "                    outputs = net(temp)\n",
    "                loss = criterion_net(outputs, targets)\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                    test_loss, correct, len(testloader.dataset),\n",
    "                    100. * correct / (len(testloader.dataset))), end=\"\\r\")\n",
    "\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "Epoch = 10 ** 5\n",
    "\n",
    "file_path = './checkpoint/Cifar10_VGG19_Weight_ConvNormConv.pth'\n",
    "best_loss = 10000.0\n",
    "start_time = time.time()\n",
    "for epoch in range(Epoch):\n",
    "    train(epoch, 0)\n",
    "    test(epoch, 0)\n",
    "result_test()\n",
    "end_time = time.time()\n",
    "print(\"Total Time = {}\".format(end_time - start_time))\n",
    "\n",
    "for key, val in wet.state_dict().items():\n",
    "    print(val.shape)\n",
    "print(17*64*3*3*3)\n",
    "\n",
    "wet.eval()\n",
    "with torch.no_grad():\n",
    "    inputs, targets = input_matrix.to(device), target_matrix.to(device)\n",
    "    outputs = wet(inputs)\n",
    "print(outputs[0,0,:5,:5])\n",
    "print(target_matrix[0,0,:5,:5])\n",
    "print(outputs[1,0,:5,:5])\n",
    "print(target_matrix[1,0,:5,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2942af-053e-486d-b7af-8233fac64705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
